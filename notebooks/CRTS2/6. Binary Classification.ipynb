{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/CRTS2/'\n",
    "RESULTS_PATH = '../../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Feature Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use catalogue of transients with min observations\n",
    "min_obs = 5\n",
    "num_features = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3873, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loead transient features\n",
    "indir = DATA_PATH\n",
    "filename = 'transient_features_{}obs_{}feats.pickle'.format(min_obs, num_features)  \n",
    "inpath = indir + filename\n",
    "df_feat_tran = pd.read_pickle(inpath)\n",
    "df_feat_tran.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4283, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load permanent Features\n",
    "indir = DATA_PATH\n",
    "filename = 'permanent_features_{}obs_{}feats.pickle'.format(min_obs, num_features) \n",
    "inpath = indir + filename\n",
    "df_feat_perm = pd.read_pickle(inpath)\n",
    "df_feat_perm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add output class '1' to transient objects\n",
    "df_feat_tran['is_transient'] = 1\n",
    "# Add output class '0' to permanent objects\n",
    "df_feat_perm['is_transient'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "df = df_feat_tran.append(df_feat_perm, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove IDs\n",
    "df = df.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = df['is_transient'].unique()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain X and y\n",
    "X = df.drop(['is_transient'], axis=1).as_matrix()\n",
    "y = df['is_transient'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in Test & Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5464, 28), (5464,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2692, 28), (2692,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create scaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_validate_model(model, params, X_train, y_train, X_test, y_test):\n",
    "    clf = GridSearchCV(model, tuned_parameters, cv=StratifiedKFold(2))\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('Best Score:', clf.best_score_)\n",
    "    print('Best Estimator:', clf.best_estimator_)\n",
    "    print('Test Score:', clf.score(X_test, y_test))\n",
    "    print('Confusion Matrix:', clf.score(X_test, y_test))\n",
    "    return clf\n",
    "\n",
    "def clf_confusion_matrix(clf, X_test, y_test, normalized=False):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred, all_labels)\n",
    "    if normalized:\n",
    "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        cnf_matrix = np.around(cnf_matrix, decimals=4) * 100\n",
    "    return cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify using SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma':[1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 1.0\n",
      "Best Estimator: SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Test Score: 1.0\n",
      "Confusion Matrix: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "clf1 = train_validate_model(model, tuned_parameters, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify using RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 1.0\n",
      "Best Estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Test Score: 1.0\n",
      "Confusion Matrix: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "clf2 = train_validate_model(model, tuned_parameters, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {\n",
    "    'learning_rate': ['constant', \"adaptive\"],\n",
    "    'hidden_layer_sizes': [(100), (100,100)],\n",
    "    'alpha': [1e-2, 1e-3, 1e-4],\n",
    "    'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 1.0\n",
      "Best Estimator: MLPClassifier(activation='logistic', alpha=0.01, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=100, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Test Score: 1.0\n",
      "Confusion Matrix: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "clf3 = train_validate_model(model, tuned_parameters, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(filepath):\n",
    "    with open(filepath, 'a') as file:\n",
    "        file.write('----- EXPERIMENT START ------\\n')\n",
    "        file.write('NUM OBSERVATIONS:{}\\n'.format(min_obs))\n",
    "        file.write('NUM FEATURES:{}\\n'.format(X_train.shape[1]))\n",
    "        file.write('FEATURES:{}\\n'.format(df.columns.values))\n",
    "        file.write('--SVM--\\n')\n",
    "        file.write('Validation Score:{}\\n'.format(clf1.best_score_))\n",
    "        file.write('Best Estimator:{}\\n'.format(clf1.best_estimator_))\n",
    "        file.write('Test Score:{}\\n'.format(clf1.score(X_test, y_test)))\n",
    "        file.write('Confusion Matrix:\\n{}\\n'.format(clf_confusion_matrix(clf1, X_test, y_test)))\n",
    "        file.write('Norm. Confusion Matrix:\\n{}\\n{}\\n'.format(all_labels, clf_confusion_matrix(clf1, X_test, y_test, True)))\n",
    "        file.write('--Random Forest--\\n')\n",
    "        file.write('Best Score:{}\\n'.format(clf2.best_score_))\n",
    "        file.write('Best Estimator:{}\\n'.format(clf2.best_estimator_))\n",
    "        file.write('Test Score:{}\\n'.format(clf2.score(X_test, y_test)))\n",
    "        file.write('Confusion Matrix:\\n{}\\n'.format(clf_confusion_matrix(clf2, X_test, y_test)))\n",
    "        file.write('Norm. Confusion Matrix:\\n{}\\n{}\\n'.format(all_labels, clf_confusion_matrix(clf2, X_test, y_test, True)))\n",
    "        file.write('--Neural Network--\\n')\n",
    "        file.write('Best Score:{}\\n'.format(clf3.best_score_))\n",
    "        file.write('Best Estimator:{}\\n'.format(clf3.best_estimator_))\n",
    "        file.write('Test Score:{}\\n'.format(clf3.score(X_test, y_test)))\n",
    "        file.write('Confusion Matrix:\\n{}\\n'.format(clf_confusion_matrix(clf3, X_test, y_test)))\n",
    "        file.write('Norm. Confusion Matrix:\\n{}\\n{}\\n'.format(all_labels, clf_confusion_matrix(clf3, X_test, y_test, True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '2-class.pickle'\n",
    "outdir = RESULTS_PATH; filepath = outdir + filename\n",
    "write_results(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
