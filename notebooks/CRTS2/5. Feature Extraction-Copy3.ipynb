{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/CRTS2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import measurements, extract\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451474, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'transient_lightcurves.pickle'\n",
    "indir = DATA_PATH; filepath = indir + filename\n",
    "df_tra = pd.read_pickle(filepath)\n",
    "df_tra.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimum number of observations for each light curve used\n",
    "min_obs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows of blended observations\n",
    "df_tra = df_tra.drop_duplicates(['TransientID','MJD'], keep='first')\n",
    "# Add observation count to every transient\n",
    "df_count = df_tra.groupby('TransientID', as_index=False).count()\n",
    "df_count['ObsCount'] = df_count['Mag']\n",
    "df_count = df_count[['TransientID', 'ObsCount']]\n",
    "df_tra = df_tra.merge(df_count, how='inner')\n",
    "# Remove objects with less than min_obs\n",
    "df_tra = df_tra[df_tra.ObsCount >= min_obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import non-transient light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1924409, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'permanent_lightcurves.pickle'\n",
    "indir = DATA_PATH; filepath = indir + filename\n",
    "df_per = pd.read_pickle(filepath)\n",
    "df_per.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter non-transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788967, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows of blended observations\n",
    "df_per = df_per.drop_duplicates(['ID','MJD'], keep='first')\n",
    "# Add observation count to every permanent\n",
    "df_count = df_per.groupby('ID', as_index=False).count()\n",
    "df_count['ObsCount'] = df_count['Mag']\n",
    "df_count = df_count[['ID', 'ObsCount']]\n",
    "df_per = df_per.merge(df_count, how='inner')\n",
    "# Remove objects with less than 5 observations\n",
    "df_per = df_per[df_per.ObsCount >= min_obs]\n",
    "df_per.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3727,), (480536, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample non-transient subset of same size as transients\n",
    "sample_size = df_tra.TransientID.unique().shape[0]\n",
    "IDs = np.random.choice(df_per.ID.unique(), size=sample_size, replace=False)\n",
    "df_per = df_per[df_per.ID.isin(IDs)]\n",
    "df_per.ID.unique().shape, df_per.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature dict creation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_dict(num_features=21):\n",
    "    features = [\n",
    "        'ID', 'skew', 'std', 'kurtosis', 'beyond1st', 'stetson_j', 'stetson_k', 'max_slope',\n",
    "        'amplitude', 'median_absolute_deviation', 'median_buffer_range_percentage', 'pair_slope_trend',\n",
    "         'flux_percentile_ratio_mid20', 'flux_percentile_ratio_mid35', 'flux_percentile_ratio_mid50',\n",
    "         'flux_percentile_ratio_mid65', 'flux_percentile_ratio_mid80', 'percent_amplitude',\n",
    "         'percent_difference_flux_percentile', 'linear_trend', 'percent_difference_flux_percentile', 'linear_trend'\n",
    "    ]\n",
    "    if num_features > 21:\n",
    "        features.append(['poly1_a','poly2_a','poly2_b','poly3_a','poly3_b','poly3_c'])\n",
    "    if num_features > 27:\n",
    "         features.append(['poly4_a', 'poly4_b', 'poly4_c', 'poly4_d'])\n",
    "    return { k:[] for k in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define number of features to be extracted\n",
    "num_features = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract transient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create empty feature dict\n",
    "tran_feats = feature_dict(num_features)\n",
    "for trID in df_tra.TransientID.unique():\n",
    "    # Get current object light curve\n",
    "    df = df_tra[df_tra.TransientID == trID]\n",
    "    # Get features\n",
    "    obj_feats = extract.features(df, feature_dict)\n",
    "    # Append features\n",
    "    for k,v in tran_feats.items():\n",
    "        if k != 'ID': tran_feats[k].append(obj_feats[k])\n",
    "    tran_feats['ID'].append(trID)\n",
    "# Create feature dataframe\n",
    "df_feat_tran = pd.DataFrame(tran_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                    3727\n",
       "amplitude                             3727\n",
       "beyond1st                             3727\n",
       "flux_percentile_ratio_mid20           3727\n",
       "flux_percentile_ratio_mid35           3727\n",
       "flux_percentile_ratio_mid50           3727\n",
       "flux_percentile_ratio_mid65           3727\n",
       "flux_percentile_ratio_mid80           3727\n",
       "kurtosis                              3727\n",
       "linear_trend                          3727\n",
       "max_slope                             3727\n",
       "median_absolute_deviation             3727\n",
       "median_buffer_range_percentage        3727\n",
       "pair_slope_trend                      3727\n",
       "percent_amplitude                     3727\n",
       "percent_difference_flux_percentile    3727\n",
       "skew                                  3727\n",
       "std                                   3727\n",
       "stetson_j                             3727\n",
       "stetson_k                             3727\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_tran.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of unique features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                    3727\n",
       "amplitude                             3498\n",
       "beyond1st                             1749\n",
       "flux_percentile_ratio_mid20           3615\n",
       "flux_percentile_ratio_mid35           3615\n",
       "flux_percentile_ratio_mid50           3615\n",
       "flux_percentile_ratio_mid65           3615\n",
       "flux_percentile_ratio_mid80           3615\n",
       "kurtosis                              3615\n",
       "linear_trend                          3615\n",
       "max_slope                             3567\n",
       "median_absolute_deviation             3615\n",
       "median_buffer_range_percentage        1569\n",
       "pair_slope_trend                      1319\n",
       "percent_amplitude                     3604\n",
       "percent_difference_flux_percentile    3615\n",
       "skew                                  3615\n",
       "std                                   3615\n",
       "stetson_j                             3615\n",
       "stetson_k                             3615\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_tran.T.apply(lambda x: x.nunique(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save transient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = df_feat_tran.shape[1]-1\n",
    "outdir = DATA_PATH\n",
    "filename = 'transient_features_{}obs_{}feats.pickle'.format(min_obs, num_features) \n",
    "outpath = outdir + filename\n",
    "df_feat_tran.to_pickle(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract permanent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty feature dict\n",
    "nontran_feats = feature_dict(num_features)\n",
    "for ID in df_per.ID.unique():\n",
    "    # Get current object light curve\n",
    "    df = df_per[df_per.ID == ID]\n",
    "    # Get features\n",
    "    obj_feats = extract.features(df, feature_dict)\n",
    "    # Append features\n",
    "    for k,v in nontran_feats.items():\n",
    "        if k != 'ID': nontran_feats[k].append(obj_feats[k])\n",
    "    nontran_feats['ID'].append(trID)\n",
    "# Create feature dataframe\n",
    "df_feat_nontran = pd.DataFrame(nontran_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                    3727\n",
       "amplitude                             3727\n",
       "beyond1st                             3727\n",
       "flux_percentile_ratio_mid20           3727\n",
       "flux_percentile_ratio_mid35           3727\n",
       "flux_percentile_ratio_mid50           3727\n",
       "flux_percentile_ratio_mid65           3727\n",
       "flux_percentile_ratio_mid80           3727\n",
       "kurtosis                              3727\n",
       "linear_trend                          3727\n",
       "max_slope                             3727\n",
       "median_absolute_deviation             3727\n",
       "median_buffer_range_percentage        3727\n",
       "pair_slope_trend                      3727\n",
       "percent_amplitude                     3727\n",
       "percent_difference_flux_percentile    3727\n",
       "skew                                  3727\n",
       "std                                   3727\n",
       "stetson_j                             3727\n",
       "stetson_k                             3727\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_nontran.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of unique features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                       1\n",
       "amplitude                              830\n",
       "beyond1st                             1818\n",
       "flux_percentile_ratio_mid20           3700\n",
       "flux_percentile_ratio_mid35           3721\n",
       "flux_percentile_ratio_mid50           3722\n",
       "flux_percentile_ratio_mid65           3721\n",
       "flux_percentile_ratio_mid80           3716\n",
       "kurtosis                              3727\n",
       "linear_trend                          3727\n",
       "max_slope                             3668\n",
       "median_absolute_deviation             3725\n",
       "median_buffer_range_percentage        1999\n",
       "pair_slope_trend                      1450\n",
       "percent_amplitude                     2080\n",
       "percent_difference_flux_percentile    3235\n",
       "skew                                  3727\n",
       "std                                   3727\n",
       "stetson_j                             3727\n",
       "stetson_k                             3727\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_nontran.T.apply(lambda x: x.nunique(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save permanent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = df_feat_nontran.shape[1]-1\n",
    "outdir = DATA_PATH\n",
    "filename = 'permanent_features_{}obs_{}feats.pickle'.format(min_obs, num_features) \n",
    "outpath = outdir + filename\n",
    "df_feat_nontran.to_pickle(outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
