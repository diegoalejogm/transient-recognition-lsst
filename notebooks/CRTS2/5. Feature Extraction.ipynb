{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/CRTS2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import measurements\n",
    "import astropy.time as astime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451474, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'transient_lightcurves.pickle'\n",
    "indir = DATA_PATH; filepath = indir + filename\n",
    "df_tra = pd.read_pickle(filepath)\n",
    "df_tra.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete rows of blended observations\n",
    "df_tra = df_tra.drop_duplicates(['TransientID','MJD'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add observation count to every transient\n",
    "df_count = df_tra.groupby('TransientID', as_index=False).count()\n",
    "df_count['ObsCount'] = df_count['Mag']\n",
    "df_count = df_count[['TransientID', 'ObsCount']]\n",
    "df_tra = df_tra.merge(df_count, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove objects with less than 5 observations\n",
    "df_tra = df_tra[df_tra.ObsCount >= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import permanent lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1924409, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'permanent_lightcurves.pickle'\n",
    "indir = DATA_PATH; filepath = indir + filename\n",
    "df_per = pd.read_pickle(filepath)\n",
    "df_per.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1802695, 4)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows of blended observations\n",
    "df_per = df_per.drop_duplicates(['ID','MJD'], keep='first')\n",
    "df_per.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add observation count to every permanent\n",
    "df_count = df_per.groupby('ID', as_index=False).count()\n",
    "df_count['ObsCount'] = df_count['Mag']\n",
    "df_count = df_count[['ID', 'ObsCount']]\n",
    "df_per = df_per.merge(df_count, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1798465, 5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove objects with less than 5 observations\n",
    "df_per = df_per[df_per.ObsCount >= 5]\n",
    "df_per.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15193,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per.ID.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501967, 5)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample subset of same size as transients\n",
    "sample_size = df_tra.TransientID.unique().shape[0]\n",
    "IDs = np.random.choice(df_per.ID.unique(), size=sample_size, replace=False)\n",
    "df_per = df_per[df_per.ID.isin(IDs)]\n",
    "df_per.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define extract features functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df, feature_dict):\n",
    "    df = df.copy()\n",
    "    df['Flux'] = measurements.__mag_to_flux__(df.Mag)\n",
    "    df['Date'] = astime.Time(df.MJD, format='mjd').datetime\n",
    "    df = df.sort_values('Date')\n",
    "    feature_dict['skew'].append(measurements.skew(df.Mag))\n",
    "    feature_dict['kurtosis'].append(measurements.kurtosis(df.Mag))\n",
    "    feature_dict['std'].append(measurements.std(df.Mag))\n",
    "    feature_dict['beyond1st'].append(measurements.beyond1st(df.Mag, df.Magerr))\n",
    "    feature_dict['stetson_j'].append(measurements.stetson_j(df.Mag, df.Magerr, df.Date))\n",
    "    feature_dict['stetson_k'].append(measurements.stetson_k(df.Mag, df.Magerr))\n",
    "    feature_dict['max_slope'].append(measurements.max_slope(df.Mag, df.Date))\n",
    "    feature_dict['amplitude'].append(measurements.amplitude(df.Mag))\n",
    "    feature_dict['median_absolute_deviation'].append(measurements.median_absolute_deviation(df.Mag))\n",
    "    feature_dict['median_buffer_range_percentage'].append(measurements.median_buffer_range_percentage(df.Flux))\n",
    "    feature_dict['pair_slope_trend'].append(measurements.pair_slope_trend(df.Mag, df.Date))\n",
    "    feature_dict['flux_percentile_ratio_mid20'].append(measurements.flux_percentile_ratio_mid20(df.Flux))\n",
    "    feature_dict['flux_percentile_ratio_mid35'].append(measurements.flux_percentile_ratio_mid35(df.Flux))\n",
    "    feature_dict['flux_percentile_ratio_mid50'].append(measurements.flux_percentile_ratio_mid50(df.Flux))\n",
    "    feature_dict['flux_percentile_ratio_mid65'].append(measurements.flux_percentile_ratio_mid65(df.Flux))\n",
    "    feature_dict['flux_percentile_ratio_mid80'].append(measurements.flux_percentile_ratio_mid80(df.Flux))\n",
    "    feature_dict['percent_amplitude'].append(measurements.percent_amplitude(df.Flux))\n",
    "    feature_dict['percent_difference_flux_percentile'].append(measurements.percent_difference_flux_percentile(df.Flux))\n",
    "    feature_dict['linear_trend'].append(measurements.linear_trend(df.Flux, df.Date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract transient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dict = {'ID':[], 'skew':[], 'std':[], 'kurtosis':[], 'beyond1st':[],'stetson_j':[], 'stetson_k':[], 'max_slope':[],'amplitude':[], 'median_absolute_deviation':[], 'median_buffer_range_percentage':[], 'pair_slope_trend':[], 'flux_percentile_ratio_mid20':[], 'flux_percentile_ratio_mid35':[], 'flux_percentile_ratio_mid50':[], 'flux_percentile_ratio_mid65':[], 'flux_percentile_ratio_mid80':[], 'percent_amplitude':[], 'percent_difference_flux_percentile':[], 'linear_trend':[]}\n",
    "for trID in df_tra.TransientID.unique():\n",
    "    df = df_tra[df_tra.TransientID == trID]\n",
    "    feature_dict['ID'].append(trID)\n",
    "    extract_features(df, feature_dict)\n",
    "df_feat_tran = pd.DataFrame(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                    4384\n",
       "amplitude                             4384\n",
       "beyond1st                             4384\n",
       "flux_percentile_ratio_mid20           4384\n",
       "flux_percentile_ratio_mid35           4384\n",
       "flux_percentile_ratio_mid50           4384\n",
       "flux_percentile_ratio_mid65           4384\n",
       "flux_percentile_ratio_mid80           4384\n",
       "kurtosis                              4384\n",
       "linear_trend                          4384\n",
       "max_slope                             4384\n",
       "median_absolute_deviation             4384\n",
       "median_buffer_range_percentage        4384\n",
       "pair_slope_trend                      4384\n",
       "percent_amplitude                     4384\n",
       "percent_difference_flux_percentile    4384\n",
       "skew                                  4384\n",
       "std                                   4384\n",
       "stetson_j                             4384\n",
       "stetson_k                             4384\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_tran.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save transient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = DATA_PATH\n",
    "filename = 'transient_features.pickle' \n",
    "outpath = outdir + filename\n",
    "df_feat_tran.to_pickle(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract permanent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dict = {'ID':[], 'skew':[], 'std':[], 'kurtosis':[], 'beyond1st':[],'stetson_j':[], 'stetson_k':[], 'max_slope':[],'amplitude':[], 'median_absolute_deviation':[], 'median_buffer_range_percentage':[], 'pair_slope_trend':[], 'flux_percentile_ratio_mid20':[], 'flux_percentile_ratio_mid35':[], 'flux_percentile_ratio_mid50':[], 'flux_percentile_ratio_mid65':[], 'flux_percentile_ratio_mid80':[], 'percent_amplitude':[], 'percent_difference_flux_percentile':[], 'linear_trend':[]}\n",
    "for ID in df_per.ID.unique():\n",
    "    df = df_per[df_per.ID == ID]\n",
    "    feature_dict['ID'].append(ID)\n",
    "    extract_features(df, feature_dict)\n",
    "df_feat_perm = pd.DataFrame(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                    4384\n",
       "amplitude                             4384\n",
       "beyond1st                             4384\n",
       "flux_percentile_ratio_mid20           4384\n",
       "flux_percentile_ratio_mid35           4384\n",
       "flux_percentile_ratio_mid50           4384\n",
       "flux_percentile_ratio_mid65           4384\n",
       "flux_percentile_ratio_mid80           4384\n",
       "kurtosis                              4384\n",
       "linear_trend                          4384\n",
       "max_slope                             4384\n",
       "median_absolute_deviation             4384\n",
       "median_buffer_range_percentage        4384\n",
       "pair_slope_trend                      4384\n",
       "percent_amplitude                     4384\n",
       "percent_difference_flux_percentile    4384\n",
       "skew                                  4384\n",
       "std                                   4384\n",
       "stetson_j                             4384\n",
       "stetson_k                             4384\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_perm.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save permanent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = DATA_PATH\n",
    "filename = 'permanent_features.pickle' \n",
    "outpath = outdir + filename\n",
    "df_feat_perm.to_pickle(outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
